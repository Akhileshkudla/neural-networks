{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulbasar/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/cifar-10-batches-py/data_batch_1\n",
      "/data/cifar-10-batches-py/data_batch_2\n",
      "/data/cifar-10-batches-py/data_batch_3\n",
      "/data/cifar-10-batches-py/data_batch_4\n",
      "/data/cifar-10-batches-py/data_batch_5\n",
      "/data/cifar-10-batches-py/test_batch\n",
      "X_train: (50000, 32, 32, 3) \n",
      "X_test: (10000, 32, 32, 3) \n",
      "y_train:  (50000,) \n",
      "y_test: (10000,) \n",
      "labels:  ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "import os, pickle\n",
    "import pickle\n",
    "\n",
    "def cifar10(data_path):\n",
    "\n",
    "    def _load_data_(files):\n",
    "        X = np.empty([0, 3072])\n",
    "        y = np.empty([0])\n",
    "        for path in files:\n",
    "            print(path)\n",
    "            with open(path, \"rb\") as f:\n",
    "                d = pickle.load(f, encoding='bytes')\n",
    "                X = np.vstack([X, d[b\"data\"]]).astype(\"uint8\")\n",
    "                y = np.hstack([y, d[b\"labels\"]]).astype(\"uint8\")\n",
    "        return X, y\n",
    "    \n",
    "    training_files = [os.path.join(data_path, \"data_batch_{0}\".format(i))  for i in range(1, 6)]\n",
    "    test_files = [os.path.join(data_path, \"test_batch\")]\n",
    "    labels_file = os.path.join(data_path, \"batches.meta\")\n",
    "\n",
    "    X_train, y_train = _load_data_(training_files)\n",
    "    X_test, y_test = _load_data_(test_files)\n",
    "\n",
    "    X_train = X_train.reshape([-1, 3, 32, 32]).transpose([0, 2, 3, 1])/255\n",
    "    X_test = X_test.reshape([-1, 3, 32, 32]).transpose([0, 2, 3, 1])/255\n",
    "\n",
    "    with open(labels_file, \"rb\") as f:\n",
    "        labels = pickle.load(f, encoding=\"bytes\")\n",
    "    labels = [s.decode(\"utf-8\")  for s in labels[b'label_names']]\n",
    "    return X_train, X_test, y_train, y_test, labels\n",
    "\n",
    "X_train, X_test, y_train, y_test, labels = cifar10(\"/data/cifar-10-batches-py/\")\n",
    "print(\"X_train:\", X_train.shape, \n",
    "      \"\\nX_test:\", X_test.shape, \n",
    "      \"\\ny_train: \", y_train.shape, \n",
    "      \"\\ny_test:\", y_test.shape, \n",
    "      \"\\nlabels: \", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = keras.utils.to_categorical(y_train)\n",
    "Y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 32)        2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               230500    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 252,438\n",
      "Trainable params: 252,438\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.6698 - acc: 0.3998 - val_loss: 1.4227 - val_acc: 0.4830\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 1.3165 - acc: 0.5339 - val_loss: 1.2693 - val_acc: 0.5548\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 1.1824 - acc: 0.5855 - val_loss: 1.1779 - val_acc: 0.5768\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 1.0970 - acc: 0.6169 - val_loss: 1.1283 - val_acc: 0.6064\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 1.0271 - acc: 0.6417 - val_loss: 1.0326 - val_acc: 0.6411\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.9744 - acc: 0.6610 - val_loss: 1.0819 - val_acc: 0.6256\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.9269 - acc: 0.6801 - val_loss: 0.9896 - val_acc: 0.6570\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.8885 - acc: 0.6931 - val_loss: 0.9541 - val_acc: 0.6686\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.8474 - acc: 0.7083 - val_loss: 0.9368 - val_acc: 0.6716\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.8092 - acc: 0.7216 - val_loss: 0.9174 - val_acc: 0.6865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x181ac2dcf8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.set_random_seed(1)\n",
    "np.random.seed(1)\n",
    "num_classes = len(labels)\n",
    "\n",
    "def build_model(input_shape, num_classes):\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Conv2D(activation=\"relu\", \n",
    "                            filters=32, \n",
    "                            kernel_size=(5, 5), \n",
    "                            input_shape = input_shape))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Conv2D(activation=\"relu\", \n",
    "                        filters=64, \n",
    "                        kernel_size=(3, 3)))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    #model.add(layers.Dropout(rate=0.8))\n",
    "    model.add(layers.Dense(100, activation=\"relu\"))\n",
    "    model.add(layers.Dense(num_classes, activation=\"softmax\"))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy\n",
    "                  , metrics=[\"accuracy\"]\n",
    "                  , optimizer=\"adam\")\n",
    "    return model\n",
    "\n",
    "model = build_model(X_train.shape[1:], num_classes)\n",
    "model.summary()\n",
    "\n",
    "model.fit(x=X_train\n",
    "          , y = Y_train\n",
    "          , validation_data = (X_test, Y_test)\n",
    "          , batch_size = 256\n",
    "          , epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
