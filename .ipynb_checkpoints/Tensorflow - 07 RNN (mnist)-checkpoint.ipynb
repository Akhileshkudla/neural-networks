{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = \"https://raw.githubusercontent.com/abulbasar/machine-learning/master/Utils.py\"\n",
    "exec(requests.get(url).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_csv(path = \"/data/MNIST/\", one_hot = False, shape = None):\n",
    "    df_train = pd.read_csv(path + \"mnist_train.csv\", header=None)\n",
    "    df_test = pd.read_csv(path + \"mnist_test.csv\", header=None)\n",
    "    \n",
    "    X_train = df_train.iloc[:, 1:].values/255\n",
    "    X_test = df_test.iloc[:, 1:].values/255\n",
    "    y_train = df_train.iloc[:, 0].values\n",
    "    y_test = df_test.iloc[:, 0].values\n",
    "    \n",
    "    if shape == \"2D\":\n",
    "        X_train = X_train.reshape(-1, 28, 28)\n",
    "        X_test = X_test.reshape(-1, 28, 28)\n",
    "    \n",
    "    if one_hot:\n",
    "        eye = np.eye(len(np.unique(y_train)))\n",
    "        y_train, y_test = eye[y_train], eye[y_test]\n",
    "        \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_mnist_csv(shape = \"2D\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:  [<tf.Tensor 'rnn/cond/Merge:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/cond_1/Merge:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/cond_2/Merge:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/cond_3/Merge:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/cond_4/Merge:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/cond_5/Merge:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/cond_6/Merge:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/cond_7/Merge:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/cond_8/Merge:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/cond_9/Merge:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/cond_10/Merge:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/cond_11/Merge:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/cond_12/Merge:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/cond_13/Merge:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/cond_14/Merge:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/cond_15/Merge:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/cond_16/Merge:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/cond_17/Merge:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/cond_18/Merge:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/cond_19/Merge:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/cond_20/Merge:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/cond_21/Merge:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/cond_22/Merge:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/cond_23/Merge:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/cond_24/Merge:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/cond_25/Merge:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/cond_26/Merge:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/cond_27/Merge:0' shape=(?, 400) dtype=float32>]\n",
      "States:  Tensor(\"rnn/cond_27/Merge_1:0\", shape=(?, 400), dtype=float32)\n",
      "epoch:  0, progress: 100%, cost: 0.22024, train acc: 0.9400\n",
      "Test accuracy: 0.9140\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "n_steps = 28\n",
    "n_inputs = 28\n",
    "state_size = 400\n",
    "n_outputs = 10\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "X_sequence = tf.unstack(X, axis=-1)\n",
    "\n",
    "cell = tf.contrib.rnn.BasicRNNCell(num_units=state_size, activation=tf.nn.tanh)\n",
    "\n",
    "nrows = tf.shape(X)[0]\n",
    "\n",
    "#initial_state = cell.zero_state(batch_size=nrows, dtype=tf.float32)\n",
    "initial_state = tf.truncated_normal(shape=(nrows, state_size), dtype=tf.float32, stddev=0.1)\n",
    "\n",
    "outputs, states = tf.nn.static_rnn(cell, X_sequence, initial_state=initial_state,  dtype=tf.float32)\n",
    "print(\"Outputs: \", outputs)\n",
    "print(\"States: \", states)\n",
    "\n",
    "logits = tf.layers.dense(states, n_outputs)\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "cost = tf.reduce_mean(xentropy)\n",
    "opt = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "y_pred = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
    "correct = tf.equal(y, y_pred)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 150\n",
    "\n",
    "m = len(X_train)\n",
    "num_batches = math.ceil(m/batch_size)\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for i in range(epochs):\n",
    "        indices = np.arange(m)\n",
    "        np.random.shuffle(indices)\n",
    "        X_train = X_train[indices]\n",
    "        y_train = y_train[indices]\n",
    "        for j in range(num_batches):\n",
    "            X_batch = X_train[j * batch_size: (j+1) * batch_size]\n",
    "            y_batch = y_train[j * batch_size: (j+1) * batch_size]\n",
    "            _, cost_, acc_train = sess.run([opt, cost, accuracy], feed_dict={X: X_batch, y: y_batch})\n",
    "            progress = (j+1)*100//num_batches\n",
    "            print(\"epoch: %2d, progress: %3d%%, cost: %.5f, train acc: %.4f\" % (i, progress, cost_, acc_train), end=\"\\r\")\n",
    "\n",
    "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "        print(\"\\nTest accuracy: %.4f\" % acc_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:  [<tf.Tensor 'rnn/basic_lstm_cell/Mul_2:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/basic_lstm_cell/Mul_5:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/basic_lstm_cell/Mul_8:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/basic_lstm_cell/Mul_11:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/basic_lstm_cell/Mul_14:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/basic_lstm_cell/Mul_17:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/basic_lstm_cell/Mul_20:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/basic_lstm_cell/Mul_23:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/basic_lstm_cell/Mul_26:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/basic_lstm_cell/Mul_29:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/basic_lstm_cell/Mul_32:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/basic_lstm_cell/Mul_35:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/basic_lstm_cell/Mul_38:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/basic_lstm_cell/Mul_41:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/basic_lstm_cell/Mul_44:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/basic_lstm_cell/Mul_47:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/basic_lstm_cell/Mul_50:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/basic_lstm_cell/Mul_53:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/basic_lstm_cell/Mul_56:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/basic_lstm_cell/Mul_59:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/basic_lstm_cell/Mul_62:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/basic_lstm_cell/Mul_65:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/basic_lstm_cell/Mul_68:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/basic_lstm_cell/Mul_71:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/basic_lstm_cell/Mul_74:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/basic_lstm_cell/Mul_77:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/basic_lstm_cell/Mul_80:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/basic_lstm_cell/Mul_83:0' shape=(?, 400) dtype=float32>]\n",
      "States:  LSTMStateTuple(c=<tf.Tensor 'rnn/basic_lstm_cell/Add_55:0' shape=(?, 400) dtype=float32>, h=<tf.Tensor 'rnn/basic_lstm_cell/Mul_83:0' shape=(?, 400) dtype=float32>)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Layer dense_1 expects 1 inputs, but it received 2 input tensors. Inputs received: [<tf.Tensor 'rnn/basic_lstm_cell/Add_55:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/basic_lstm_cell/Mul_83:0' shape=(?, 400) dtype=float32>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-c88e291cf6d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"States: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mxentropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_softmax_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/core.py\u001b[0m in \u001b[0;36mdense\u001b[0;34m(inputs, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, trainable, name, reuse)\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0m_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                 _reuse=reuse)\n\u001b[0;32m--> 248\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m       \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m     \"\"\"\n\u001b[0;32m--> 809\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m   def _add_inbound_node(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m           \u001b[0;31m# Check input assumptions set before layer building, e.g. input rank.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m_assert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1157\u001b[0m                        \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' inputs, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m                        \u001b[0;34m'but it received '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                        ' input tensors. Inputs received: ' + str(inputs))\n\u001b[0m\u001b[1;32m   1160\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minput_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Layer dense_1 expects 1 inputs, but it received 2 input tensors. Inputs received: [<tf.Tensor 'rnn/basic_lstm_cell/Add_55:0' shape=(?, 400) dtype=float32>, <tf.Tensor 'rnn/basic_lstm_cell/Mul_83:0' shape=(?, 400) dtype=float32>]"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "n_steps = 28\n",
    "n_inputs = 28\n",
    "state_size = 400\n",
    "n_outputs = 10\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "X_sequence = tf.unstack(X, axis=-1)\n",
    "\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units=state_size, activation=tf.nn.tanh)\n",
    "\n",
    "outputs, states = tf.nn.static_rnn(cell, X_sequence, dtype=tf.float32)\n",
    "print(\"Outputs: \", outputs)\n",
    "print(\"States: \", states)\n",
    "\n",
    "logits = tf.layers.dense(states, n_outputs)\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "cost = tf.reduce_mean(xentropy)\n",
    "opt = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "y_pred = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
    "correct = tf.equal(y, y_pred)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 150\n",
    "\n",
    "m = len(X_train)\n",
    "num_batches = math.ceil(m/batch_size)\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for i in range(epochs):\n",
    "        indices = np.arange(m)\n",
    "        np.random.shuffle(indices)\n",
    "        X_train = X_train[indices]\n",
    "        y_train = y_train[indices]\n",
    "        for j in range(num_batches):\n",
    "            X_batch = X_train[j * batch_size: (j+1) * batch_size]\n",
    "            y_batch = y_train[j * batch_size: (j+1) * batch_size]\n",
    "            _, cost_, acc_train = sess.run([opt, cost, accuracy], feed_dict={X: X_batch, y: y_batch})\n",
    "            progress = (j+1)*100//num_batches\n",
    "            print(\"epoch: %2d, progress: %3d%%, cost: %.5f, train acc: %.4f\" % (i, progress, cost_, acc_train), end=\"\\r\")\n",
    "\n",
    "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "        print(\"\\nTest accuracy: %.4f\" % acc_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
